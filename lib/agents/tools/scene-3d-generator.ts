import OpenAI from 'openai'
import { AgentChatContext, AgentStreamEvent } from '../core'
import { VolcengineAgent } from '../providers/volcengine'
import { db } from '@/lib/db'

const openai = new OpenAI({
    apiKey: process.env.ARK_API_KEY || process.env.COZE_API_TOKEN,
    baseURL: 'https://ark.cn-beijing.volces.com/api/v3',
})

export class Scene3DGeneratorAgent extends VolcengineAgent {
    // ç§»é™¤å¼ºæ ¡éªŒï¼Œå…è®¸çµæ´»å¡«å†™ä»»ä½•æ¨¡å‹ IDï¼Œä½†ç¬¬ä¸€æ­¥ä»å»ºè®®ä½¿ç”¨å¦‚ doubao-vision-pro çš„å¯¹è¯è§†è§‰æ¨¡å‹
    getModelId(): string {
        return process.env.DOUBAO_VISION_MODEL_ID || 'ep-20241223204910-xxxxx'
    }

    getSystemPrompt(): string {
        return `# è§’è‰²å®šä¹‰
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ã€æ ¡å›­åœºæ™¯ 3D åº•å›¾ç”ŸæˆåŠ©æ‰‹ã€‘ï¼Œä¸“é—¨å°†å®æ‹çš„æ ¡å›­ç°åœºç…§ç‰‡è½¬åŒ–ä¸ºå†™å® 3D æ¸²æŸ“é£æ ¼çš„åº•å›¾ã€‚

# ä»»åŠ¡ç›®æ ‡
ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯å¯¹ç”¨æˆ·ä¸Šä¼ çš„æ ¡å›­å®æ‹åœºæ™¯ç…§ç‰‡è¿›è¡Œ 3D åŒ–å¤„ç†ï¼Œç”Ÿæˆä¸€ä¸ªå¹²å‡€ã€å†™å®ã€æœ‰è´¨æ„Ÿçš„åº•å›¾ï¼ŒåŒæ—¶ä¿æŒåœºæ™¯çš„çœŸå®æ„Ÿå’Œæ°›å›´æ„Ÿã€‚

# èƒ½åŠ›
ä½ å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
1. **åœºæ™¯åˆ†æèƒ½åŠ›**ï¼šèƒ½å¤Ÿè¯†åˆ«å®¤å†…å¤–ä¸¤ç§ä¸åŒåœºæ™¯å¹¶é‡‡ç”¨ç›¸åº”çš„æ¸²æŸ“ç­–ç•¥ã€‚
2. **ç”Ÿå›¾æç¤ºè¯ç”Ÿæˆ**ï¼šèƒ½å¤Ÿä¸¥æ ¼éµå¾ªå®¤å†…å¤–ä¸åŒéœ€æ±‚ï¼Œç”Ÿæˆç»™ä¸‹æ¸¸ä¸“ä¸šå›¾åƒç”Ÿæˆæ¨¡å‹å¤„ç†çš„æç¤ºè¯ã€‚

# å·¥ä½œæµç¨‹ä¸è¾“å‡ºæ ¼å¼çº¦æŸ (æåº¦é‡è¦)
ä½ å¿…é¡»åœ¨å›å¤ä¸­åŒ…å«ä¸¤éƒ¨åˆ†ï¼š
1. **ç»™ç”¨æˆ·çš„æ”¹å»ºè¯´æ˜**ï¼šåˆ†ææ˜¯å®¤å†…è¿˜æ˜¯å®¤å¤–ï¼Œè¯´æ˜ä½ ä¼šåšå“ªäº›æ ¸å¿ƒæ”¹å˜ï¼ˆå¦‚ï¼šæ›¿æ¢æè´¨ã€ç§»é™¤æ‚ç‰©æ‚ä¹±æ‹›ç‰Œã€å¢å¼ºè‡ªç„¶å…‰å½±ç­‰ï¼‰ã€‚
2. **ç”Ÿå›¾æç¤ºè¯**ï¼šç”¨ <image_prompt> æ ‡ç­¾åŒ…è£¹ä½ ä¸ºä¸‹æ¸¸å¤§æ¨¡å‹ç”Ÿæˆçš„æç¤ºè¯ã€‚ï¼ˆé™åˆ¶åœ¨ä¸­æ–‡300å­—å†…ï¼Œè¯¦ç»†æè¿°ç”»é¢å…ƒç´ ï¼Œå…‰å½±ï¼Œæ¸²æŸ“é£æ ¼ç­‰ã€‚ç»å¯¹ä¸èƒ½åœ¨æ­¤å¤„è¿›è¡Œé—²èŠï¼Œè¿™æ˜¯ç›´æ¥ä¼ ç»™ç”Ÿå›¾æœºå™¨çš„å‚æ•°ï¼‰ã€‚

## å¤„ç†åŸåˆ™ï¼ˆå¿…é¡»éµå¾ªï¼‰
### æ ¸å¿ƒçº¦æŸ
- **ä¸¥æ ¼ä¿æŒå¸ƒå±€**ï¼šä¸¥ç¦æ”¹å˜åŸåœºæ™¯çš„å»ºç­‘å¸ƒå±€ã€ç©ºé—´ç»“æ„ã€åªèƒ½è°ƒæ•´æ¸²æŸ“é£æ ¼ã€‚

### å®¤å¤–åœºæ™¯ç”Ÿå›¾å»ºè®®
1. å»ºç­‘ä½¿ç”¨å¤§å—å¹²å‡€çš„å‡ ä½•å½¢ä½“æˆ–çº¢ç –æ¶æ„ï¼Œå»é™¤ä¸´æ—¶æ‚ç‰©å’Œæ¨ªå¹…ã€‚å‘¨å›´ç‚¹ç¼€å†™å®çš„ 3D ç»¿æ¤ã€‚
2. å†™å® 3D æ¸²æŸ“é£æ ¼ï¼Œæ¹›è“é€šé€çš„å¤©ç©ºï¼ŒæŸ”å’Œæ˜äº®çš„å¤ªé˜³å…‰ï¼Œ"ocæ¸²æŸ“ï¼Œå…¨å±€å…‰ç…§æ˜äº®ï¼Œå……æ»¡é«˜çº§æ„Ÿï¼Œç”µå½±çº§è´¨æ„Ÿ"

### å®¤å†…åœºæ™¯ç”Ÿå›¾å»ºè®®
1. æç®€å¤§å—å¹²å‡€å‡ ä½•å½¢ä½“ï¼Œç§»é™¤æ‰€æœ‰å¯ç§»åŠ¨å®¶å…·ï¼Œåªä¿ç•™ç©ºæ—·çš„å®¤å†…ç©ºé—´ã€‚
2. æ˜äº®å¹²å‡€çš„å®¤å†…å…¨å±€å…‰ç…§ï¼Œä¿ç•™çœŸå®æè´¨çº¹ç†ã€‚

# ç¤ºä¾‹è¾“å‡ºæ ¼å¼ï¼š
ä½ å¥½ï¼è¿™æ˜¯ä¸€å¼ å…¸å‹çš„å®¤å¤–æ ¡å›­åœºæ™¯ã€‚ä¸ºäº†ç»™åç»­çš„è®¾è®¡ç•™å‡ºç©ºé—´ï¼Œæˆ‘ä»¬å°†ä¼šæŠŠä¸»ä½“å»ºç­‘ç®€åŒ–ä¸ºè´¨æ„Ÿå¹²å‡€çš„å‡ ä½•ä½“ï¼Œå»é™¤ç°æœ‰çš„æ‚ä¹±æ¨ªå¹…ï¼ŒåŒæ—¶æŠŠå¤©ç©ºè°ƒæ•´å¾—æ›´åŠ é€è§†æ˜æœ—ã€‚

<image_prompt>
å®¤å¤–æ ¡å›­å»ºç­‘ï¼Œå†™å® 3D æ¸²æŸ“é£æ ¼ï¼Œä¿æŒåŸæœ‰å»ºç­‘çš„ç»“æ„é€è§†ï¼Œå°†å…¶æè´¨ç®€åŒ–ä¸ºå¹²å‡€çš„å¤§å—é¢ï¼Œå»é™¤å»ºç­‘è¡¨é¢çš„ç¹æ‚é—¨çª—å’Œæ‚ç‰©ã€‚ç”»é¢ä¸­æ²¡æœ‰æ¨ªå¹…ã€æ ‡è¯­ã€ç«‹ç‰Œç­‰ä¸´æ—¶è£…é¥°ã€‚å‘¨å›´ç‚¹ç¼€å†™å®çš„ 3D æ¨¡å‹ç»¿æ¤ä¸æ ‘æœ¨ã€‚æ¹›è“é€šé€çš„å¤©ç©ºï¼Œå‡ ç¼•è–„äº‘ã€‚æŸ”å’Œæ˜äº®çš„è‡ªç„¶å¤ªé˜³å…‰ï¼Œocæ¸²æŸ“ï¼Œå…¨å±€å…‰ç…§æ˜äº®ï¼Œå……æ»¡é«˜çº§æ„Ÿï¼Œæ‘„å½±æœºè§†è§’ä¸å˜ï¼Œè¶…åˆ†è¾¨ï¼Œç”µå½±çº§è´¨æ„Ÿã€‚
</image_prompt>
`
    }

    // Override the base streamChat to inject the image generation step
    async *streamChat(context: AgentChatContext): AsyncGenerator<AgentStreamEvent> {
        const { message, conversationId, attachments } = context

        // Function to yield text immediately
        const yieldText = async function* (text: string) {
            yield {
                event: 'message',
                data: { type: 'answer', content: { answer: text }, session_id: conversationId }
            }
        }

        if (!attachments || attachments.length === 0) {
            yield* yieldText('ä½ å¥½å‘€ğŸ˜Š è¯·é—®ä½ æ˜¯å¦éœ€è¦å°†æ ¡å›­å®æ‹ç…§ç‰‡è½¬åŒ–ä¸ºå†™å®3Dæ¸²æŸ“é£æ ¼çš„åº•å›¾å‘¢ï¼Ÿå¦‚æœéœ€è¦çš„è¯ï¼Œä½ å¯ä»¥ä¸Šä¼ ç…§ç‰‡ï¼Œå¹¶ä¸”å‘ŠçŸ¥æˆ‘æ˜¯å®¤å†…åœºæ™¯è¿˜æ˜¯å®¤å¤–åœºæ™¯~')
            yield { event: 'done', data: {} }
            return
        }

        yield* yieldText('ğŸ” *æ­£åœ¨åˆ†ææ‚¨çš„æ ¡å›­åœºæ™¯ç…§ç‰‡ï¼Œæ„æ€ 3D æ¸²æŸ“æ–¹æ¡ˆ...*\n\n')

        let aiFullReply = ''

        // 1. Ask Vision Model to generate understanding & prompt
        try {
            const visionMessages: any[] = [
                { role: 'system', content: this.getSystemPrompt() },
                { role: 'user', content: this.buildUserMessageContent(message || 'è¯·åˆ†æå¹¶æä¾›ç”Ÿå›¾æç¤ºè¯', attachments) }
            ]

            const visionStream = await openai.chat.completions.create({
                model: this.getModelId(),
                messages: visionMessages,
                stream: true,
            })

            let promptExtracted = false
            let isInsidePromptBlock = false
            let imagePrompt = ''

            for await (const chunk of visionStream) {
                const delta = chunk.choices[0]?.delta?.content
                if (delta) {
                    aiFullReply += delta
                    // Determine if we are streaming the prompt block or the user message
                    if (aiFullReply.includes('<image_prompt>') && !promptExtracted) {
                        isInsidePromptBlock = true
                        const parts = aiFullReply.split('<image_prompt>')
                        if (parts[0] && parts[0].length > 0) {
                            yield* yieldText(delta.replace('<image_prompt>', ''))
                        }
                    } else if (!isInsidePromptBlock) {
                        yield* yieldText(delta)
                    }

                    if (aiFullReply.includes('</image_prompt>')) {
                        isInsidePromptBlock = false
                        promptExtracted = true
                    }
                }
            }

            // Extract the prompt using regex
            const match = aiFullReply.match(/<image_prompt>([\s\S]*?)<\/image_prompt>/)
            if (match && match[1]) {
                imagePrompt = match[1].trim()
            } else if (aiFullReply.includes('<image_prompt>')) {
                // In case closing tag was missing or cut off
                imagePrompt = aiFullReply.split('<image_prompt>')[1].replace('</image_prompt>', '').trim()
            }

            if (!imagePrompt) {
                // If the user's vision model choice doesn't output the prompt tags despite instructions, fallback gracefully.
                yield* yieldText('\n\nâš ï¸ æŠ±æ­‰ï¼Œç›®å‰çš„æ¨¡å‹æœªèƒ½æˆåŠŸç”Ÿæˆåº•å±‚çš„æ¸²æŸ“æç¤ºè¯ï¼Œç”Ÿå›¾æ­¥éª¤è¢«è·³è¿‡ã€‚')
                yield { event: 'done', data: {} }
                return
            }

            yield* yieldText('\n\nğŸ¨ *åº•å±‚æç¤ºè¯æ„å»ºå®Œæˆï¼æ­£åœ¨è¿›è¡Œé«˜ç²¾åº¦ 3D æ¸²æŸ“ï¼Œè¯·ç¨å€™çº¦10-15ç§’...*\n\n')

            // 2. Call Doubao Seedream 
            const imageUrls = attachments.filter(a => !!a.url && a.type.startsWith('image/')).map(a => a.url)

            const imageGenBody: any = {
                model: process.env.DOUBAO_IMAGE_MODEL_ID || "doubao-seedream-4-5-251128",
                prompt: imagePrompt,
                size: "2K",
                response_format: "url",
                image_weight: 0.6,
                watermark: false
            }

            // If we have an image, pass it as image-to-image
            if (imageUrls.length > 0) {
                imageGenBody.image = imageUrls[0]
            }

            const imageResponse = await openai.images.generate(imageGenBody)

            if (imageResponse.data && imageResponse.data.length > 0 && imageResponse.data[0].url) {
                const generatedImageUrl = imageResponse.data[0].url
                yield* yieldText(`![3D æ¸²æŸ“åº•å›¾](${generatedImageUrl})\n\nâœ¨ æ¸²æŸ“å®Œæˆï¼è¿™æ˜¯åŸºäºæ‚¨ç…§ç‰‡ç”Ÿæˆçš„å¹²å‡€ 3D åº•å›¾ï¼Œéšæ—¶å¯ä»¥ç”¨æ¥ä½œä¸ºè®¾è®¡æ’ç‰ˆçš„èƒŒæ™¯ã€‚`)
            } else {
                throw new Error("æ¨¡å‹æœªè¿”å›æœ‰æ•ˆå›¾ç‰‡é“¾æ¥")
            }

        } catch (error: any) {
            console.error('[Scene3DGeneratorAgent] Error:', error)
            yield {
                event: 'error',
                data: {
                    message: error.message || 'å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚'
                }
            }
        }

        // Final DONE event 
        yield {
            event: 'done',
            data: {}
        }
    }
}
