import OpenAI from 'openai'
import { AgentChatContext, AgentStreamEvent } from '../core'
import { VolcengineAgent } from '../providers/volcengine'
import { db } from '@/lib/db'

const openai = new OpenAI({
    apiKey: process.env.ARK_API_KEY || process.env.COZE_API_TOKEN,
    baseURL: 'https://ark.cn-beijing.volces.com/api/v3',
})

export class Scene3DGeneratorAgent extends VolcengineAgent {
    // ç§»é™¤å¼ºæ ¡éªŒï¼Œå…è®¸çµæ´»å¡«å†™ä»»ä½•æ¨¡å‹ IDï¼Œä½†ç¬¬ä¸€æ­¥ä»å»ºè®®ä½¿ç”¨å¦‚ doubao-vision-pro çš„å¯¹è¯è§†è§‰æ¨¡å‹
    getModelId(): string {
        return process.env.DOUBAO_VISION_MODEL_ID || 'ep-20241223204910-xxxxx'
    }

    getSystemPrompt(): string {
        return `# è§’è‰²å®šä¹‰
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ã€æ ¡å›­åœºæ™¯ 3D åº•å›¾ç”ŸæˆåŠ©æ‰‹ã€‘ï¼Œä¸“é—¨å°†å®æ‹çš„æ ¡å›­ç°åœºç…§ç‰‡è½¬åŒ–ä¸ºå†™å® 3D æ¸²æŸ“é£æ ¼çš„åº•å›¾ã€‚

# ä»»åŠ¡ç›®æ ‡
ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯å¯¹ç”¨æˆ·ä¸Šä¼ çš„å›¾ç‰‡(ä¹Ÿå¯èƒ½æ˜¯æ ¹æ®ä½ è‡ªèº«ä¹‹å‰ç”Ÿæˆçš„å›¾)è¿›è¡ŒäºŒæ¬¡æ„å›¾è¯„ä¼°ï¼Œåœ¨ç¡®ç«‹æ¸²æŸ“æ–¹æ¡ˆåï¼Œç”Ÿæˆä¸€ä¸ªå¹²å‡€ã€å†™å®ã€æœ‰è´¨æ„Ÿçš„åº•å›¾ã€‚

# èƒ½åŠ›
ä½ å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
1. **åœºæ™¯åŠè¯­ä¹‰åˆ†æèƒ½åŠ›**ï¼šèƒ½å¤Ÿä¸²è”ä¸Šä¸‹æ–‡ï¼Œå¯¹ç”¨æˆ·çš„è¿›ä¸€æ­¥ä¿®æ”¹æ„è§è¿›è¡Œåˆ†æã€‚å¦‚æœç”¨æˆ·æå‡ºä¿®æ”¹ï¼ˆæ¯”å¦‚ï¼šç§»é™¤æŸä¸ªæŸœå­ã€æ”¹é¢œè‰²ç­‰ï¼‰ï¼Œä½ è¦èƒ½æå–å‡ºè¿™äº›è¦æ±‚ã€‚
2. **ç”Ÿå›¾æç¤ºè¯ç”Ÿæˆ**ï¼šèƒ½å¤Ÿä¸¥æ ¼éµå¾ªè¦æ±‚ï¼Œç»“åˆå›¾ç‰‡ä¸Šä¸‹æ–‡ï¼Œè¾“å‡ºå®Œæ•´ä¸°å¯Œçš„ç”Ÿå›¾æç¤ºè¯ç»™ä¸‹æ¸¸ä¸“ä¸šå›¾åƒæ¨¡å‹ã€‚

# å·¥ä½œæµç¨‹ä¸è¾“å‡ºæ ¼å¼çº¦æŸ (æåº¦é‡è¦)
ä½ å¿…é¡»åœ¨å›å¤ä¸­åŒ…å«ä¸¤éƒ¨åˆ†ï¼š
1. **ç»™ç”¨æˆ·çš„æ”¹å»ºè¯´æ˜**ï¼šè¯´æ˜ä½ ä¼šåšå“ªäº›æ ¸å¿ƒæ”¹å˜ï¼ˆå¦‚ï¼šæ›¿æ¢æè´¨ã€ç§»é™¤é»‘æ¿ã€å¢å¼ºè‡ªç„¶å…‰å½±ç­‰ï¼‰ã€‚
2. **ç”Ÿå›¾æç¤ºè¯**ï¼šç”¨ <image_prompt> æ ‡ç­¾åŒ…è£¹ä½ ä¸ºä¸‹æ¸¸å¤§æ¨¡å‹ç”Ÿæˆçš„æç¤ºè¯ã€‚ï¼ˆé™åˆ¶åœ¨ä¸­æ–‡300å­—å†…ï¼Œè¯¦ç»†æè¿°ç”»é¢å…ƒç´ ï¼Œå…‰å½±ï¼Œæ¸²æŸ“é£æ ¼ç­‰ã€‚åŠ¡å¿…ç»“åˆè¿è´¯åœºæ™¯ï¼‰ã€‚

## å¤„ç†åŸåˆ™ï¼ˆå¿…é¡»éµå¾ªï¼‰
### æ ¸å¿ƒçº¦æŸ
- **ä¸¥æ ¼ä¿æŒå¸ƒå±€**ï¼šä¸¥ç¦æ”¹å˜åŸåœºæ™¯çš„å»ºç­‘å¸ƒå±€ã€ç©ºé—´ç»“æ„ã€åªèƒ½è°ƒæ•´æ¸²æŸ“é£æ ¼å±€éƒ¨å†…å®¹ã€‚

### å®¤å¤–åœºæ™¯ç”Ÿå›¾å»ºè®®
1. å»ºç­‘ä½¿ç”¨å¤§å—å¹²å‡€çš„å‡ ä½•å½¢ä½“æˆ–çº¢ç –æ¶æ„ï¼Œå»é™¤ä¸´æ—¶æ‚ç‰©å’Œæ¨ªå¹…ã€‚å‘¨å›´ç‚¹ç¼€å†™å®çš„ 3D ç»¿æ¤ã€‚
2. å†™å® 3D æ¸²æŸ“é£æ ¼ï¼Œæ¹›è“é€šé€çš„å¤©ç©ºï¼ŒæŸ”å’Œæ˜äº®çš„å¤ªé˜³å…‰ï¼Œ"ocæ¸²æŸ“ï¼Œå…¨å±€å…‰ç…§æ˜äº®ï¼Œå……æ»¡é«˜çº§æ„Ÿï¼Œç”µå½±çº§è´¨æ„Ÿ"

### å®¤å†…åœºæ™¯ç”Ÿå›¾å»ºè®®
1. æç®€å¤§å—å¹²å‡€å‡ ä½•å½¢ä½“ï¼ŒæŒ‰ç”¨æˆ·éœ€æ±‚ç§»é™¤æˆ–ä¿ç•™ç‰¹å®šçš„å®¶å…·ç‰©ä½“ã€‚
2. æ˜äº®å¹²å‡€çš„å®¤å†…å…¨å±€å…‰ç…§ï¼Œä¿ç•™çœŸå®æè´¨çº¹ç†ã€‚

# ç¤ºä¾‹è¾“å‡ºæ ¼å¼ï¼š
å¥½çš„ï¼æˆ‘å°†æ ¹æ®æ‚¨çš„è¦æ±‚ï¼ŒæŠŠå¢™ä¸Šçš„ç»¿è‰²é»‘æ¿å’Œä¸‹æ–¹æŸœå­éƒ½ç§»é™¤æ‰ï¼Œè®©å¢™é¢ä¿æŒç©ºæ—·å†™å®ã€‚

<image_prompt>
å®¤å†…æ•™å®¤ç©ºé—´ï¼Œå†™å® 3D æ¸²æŸ“é£æ ¼ã€‚æç®€å¹²å‡€å¤§å—é¢å‡ ä½•å½¢ä½“ä¼šï¼Œå¢™é¢æ•´ä½“æ¶‚ç™½ä¸”ååˆ†ç©ºæ—·ã€‚åŸæœ¬çš„é»‘æ¿å’Œä¸‹æ–¹æŸœå­å·²ç»è¢«å®Œå…¨ç§»é™¤ã€‚æ˜äº®å¹²å‡€çš„å®¤å†…å…¨å±€å…‰ç…§ï¼Œè‡ªç„¶é˜³å…‰ä»çª—æˆ·å¤–é€å…¥ã€‚çœŸå®é«˜çº§æè´¨çº¹ç†ï¼Œocæ¸²æŸ“ï¼Œæ‘„å½±æœºè§†è§’ä¸å˜ï¼Œè¶…åˆ†è¾¨ï¼Œç”µå½±çº§è´¨æ„Ÿã€‚
</image_prompt>
`
    }

    // Override the base streamChat to inject the image generation step
    async *streamChat(context: AgentChatContext): AsyncGenerator<AgentStreamEvent> {
        const { message, conversationId, attachments } = context

        // Function to yield text immediately
        const yieldText = async function* (text: string) {
            yield {
                event: 'message',
                data: { type: 'answer', content: { answer: text }, session_id: conversationId }
            }
        }

        let referenceImageUrl = ''

        // 1. Find if the user attached a new image
        if (attachments && attachments.length > 0) {
            const img = attachments.find(a => !!a.url && a.type.startsWith('image/'))
            if (img && img.url) referenceImageUrl = img.url
        }

        // 2. If no new attachment, search DB history for the latest image (either user uploaded, or assistant generated)
        if (!referenceImageUrl && conversationId) {
            const history = await db.message.findMany({
                where: { conversationId },
                orderBy: { createdAt: 'desc' },
            })

            for (const msg of history) {
                // If assistant previously generated an image markdown
                if (msg.role === 'assistant' && msg.content) {
                    const match = msg.content.match(/!\[.*?\]\((https?:\/\/.*?)\)/)
                    if (match && match[1]) {
                        referenceImageUrl = match[1]
                        break
                    }
                }
                // If user previously uploaded an image
                if (msg.role === 'user' && msg.attachments) {
                    try {
                        const atts = JSON.parse(msg.attachments)
                        const img = atts.find((a: any) => !!a.url && a.type.startsWith('image/'))
                        if (img) {
                            referenceImageUrl = img.url
                            break
                        }
                    } catch (e) { }
                }
            }
        }

        if (!referenceImageUrl) {
            // Cannot find any image at all in current inputs or history
            yield* yieldText('ä½ å¥½å‘€ğŸ˜Š æˆ‘å¥½åƒæ²¡æœ‰æ”¶åˆ°ä»»ä½•å‚è€ƒå›¾ç‰‡ã€‚è¯·å…ˆä¸Šä¼ ä¸€å¼ æ ¡å›­ç°åœºç…§ç‰‡ï¼Œæˆ–è€…åŸºäºä¹‹å‰çš„å›¾ç‰‡å‘èµ·å¯¹è¯~')
            yield { event: 'done', data: {} }
            return
        }

        yield* yieldText('ğŸ” *æ­£åœ¨åˆ†æåœºæ™¯ä¸æ‚¨çš„æ²Ÿé€šéœ€æ±‚ï¼Œæ„æ€ 3D æ¸²æŸ“æ–¹æ¡ˆ...*\n\n')

        let aiFullReply = ''

        try {
            // Build the multi-message history so Vision model understands what we did before
            const visionMessages = await this.buildMessagesHistory(context)

            const visionStream = await openai.chat.completions.create({
                model: this.getModelId(),
                messages: visionMessages,
                stream: true,
            })

            let promptExtracted = false
            let isInsidePromptBlock = false
            let imagePrompt = ''

            for await (const chunk of visionStream) {
                const delta = chunk.choices[0]?.delta?.content
                if (delta) {
                    aiFullReply += delta
                    if (aiFullReply.includes('<image_prompt>') && !promptExtracted) {
                        isInsidePromptBlock = true
                        const parts = aiFullReply.split('<image_prompt>')
                        if (parts[0] && parts[0].length > 0) {
                            yield* yieldText(delta.replace('<image_prompt>', ''))
                        }
                    } else if (!isInsidePromptBlock) {
                        yield* yieldText(delta)
                    }

                    if (aiFullReply.includes('</image_prompt>')) {
                        isInsidePromptBlock = false
                        promptExtracted = true
                    }
                }
            }

            // Extract the prompt using regex
            const match = aiFullReply.match(/<image_prompt>([\s\S]*?)<\/image_prompt>/)
            if (match && match[1]) {
                imagePrompt = match[1].trim()
            } else if (aiFullReply.includes('<image_prompt>')) {
                // In case closing tag was missing or cut off
                imagePrompt = aiFullReply.split('<image_prompt>')[1].replace('</image_prompt>', '').trim()
            }

            if (!imagePrompt) {
                yield* yieldText('\n\nâš ï¸ æŠ±æ­‰ï¼Œç›®å‰çš„æ¨¡å‹æœªèƒ½æˆåŠŸç”Ÿæˆåº•å±‚çš„æ¸²æŸ“æç¤ºè¯ï¼Œç”Ÿå›¾æ­¥éª¤è¢«è·³è¿‡ã€‚')
                yield { event: 'done', data: {} }
                return
            }

            yield* yieldText('\n\nğŸ¨ *åº•å±‚æç¤ºè¯æ„å»ºå®Œæˆï¼æ­£åœ¨è¿›è¡Œé«˜ç²¾åº¦ 3D æ¸²æŸ“ï¼Œè¯·ç¨å€™çº¦10-15ç§’...*\n\n')

            const imageGenBody: any = {
                model: process.env.DOUBAO_IMAGE_MODEL_ID || "doubao-seedream-4-5-251128",
                prompt: imagePrompt,
                size: "2K",
                response_format: "url",
                image_weight: 0.6,
                watermark: false,
                image: referenceImageUrl // Pass the extracted reference image
            }

            const imageResponse = await openai.images.generate(imageGenBody)

            if (imageResponse.data && imageResponse.data.length > 0 && imageResponse.data[0].url) {
                const generatedImageUrl = imageResponse.data[0].url
                yield* yieldText(`![3D æ¸²æŸ“åº•å›¾](${generatedImageUrl})\n\nâœ¨ æ¸²æŸ“å®Œæˆï¼è¿™æ˜¯åŸºäºåˆšæ‰å‚è€ƒå›¾ç”Ÿæˆçš„å…¨æ–° 3D åº•å›¾ã€‚æ‚¨å¯ä»¥ç»§ç»­æå‡ºä¿®æ”¹å»ºè®®å–”ï¼`)
            } else {
                throw new Error("æ¨¡å‹æœªè¿”å›æœ‰æ•ˆå›¾ç‰‡é“¾æ¥")
            }

        } catch (error: any) {
            console.error('[Scene3DGeneratorAgent] Error:', error)
            yield {
                event: 'error',
                data: {
                    message: error.message || 'å›¾ç‰‡ç”Ÿæˆå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚'
                }
            }
        }

        // Final DONE event 
        yield {
            event: 'done',
            data: {}
        }
    }
}
