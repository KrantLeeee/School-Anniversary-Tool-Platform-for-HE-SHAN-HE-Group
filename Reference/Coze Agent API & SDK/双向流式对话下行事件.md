# 双向流式对话下行事件

> 来源: https://www.coze.cn/open/docs/developer_guides/streaming_chat_downlink_event

- 事件类型 ： chat.created ​

- 事件说明 ：流式对话接口成功建立连接后服务端会发送此事件。 ​

- 事件结构 ： ​

- ​ 参数 ​ 类型 ​ 是否必选 ​ 说明 ​ id ​ String ​ 必选 ​ 服务端生成的唯一 ID。 ​ event_type ​ String ​ 必选 ​ 固定为 chat.created 。 ​ detail ​ Object ​ 必选 ​ 事件详情。 ​ detail.logid ​ String ​ 必选 ​ 本次请求的日志 ID。如果遇到异常报错场景，且反复重试仍然报错，可以根据此 logid 及错误码联系扣子团队获取帮助。详细说明可参考获取帮助和技术支持。 ​ ​

| 参数​ | 类型​ | 是否必选​ | 说明​ |
| id​ | String​ | 必选​ | 服务端生成的唯一 ID。​ |
| event_type​ | String​ | 必选​ | 固定为chat.created。​ |
| detail​ | Object​ | 必选​ | 事件详情。​ |
| detail.logid​ | String​ | 必选​ | 本次请求的日志 ID。如果遇到异常报错场景，且反复重试仍然报错，可以根据此 logid 及错误码联系扣子团队获取帮助。详细说明可参考获取帮助和技术支持。​ |

- 事件示例： ​

- 事件类型 ： chat.updated ​

- 事件说明 ：对话配置更新成功后，会返回最新的配置。 ​

- 事件结构 ： ​

| 参数​ | 类型​ | 是否必选​ | 说明​ |
| id​ | String​ | 必选​ | 客户端自行生成的事件 ID，方便定位问题。​ |
| event_type​ | String​ | 必选​ | 固定为chat.updated。​ |
| data​ | Object​ | 必选​ | 事件数据，包含对话配置的详细信息。​ |
| data.chat_config​ | Object​ | 可选​ | 对话配置。​ |
| data.chat_config.meta_data​ | Map<String, String>​ | 可选​ | 附加信息，通常用于封装一些业务相关的字段。查看对话消息详情时，系统会透传此附加信息。自定义键值对，应指定为 Map 对象格式。长度为 16 对键值对，其中键（key）的长度范围为 1～64 个字符，值（value）的长度范围为 1～512 个字符。​ |
| data.chat_config.custom_variables​ | Map<String, String>​ | 可选​ | 智能体中定义的变量。在智能体 prompt 中设置变量 {{key}} 后，可以通过该参数传入变量值，同时支持 Jinja2 语法。详细说明可参考变量示例。变量名只支持英文字母和下划线。​ |
| data.chat_config.extra_params​ | Map<String, String>​ | 可选​ | 附加参数，通常用于特殊场景下指定一些必要参数供模型判断，例如指定经纬度，并询问智能体此位置的天气。自定义键值对格式，其中键（key）仅支持设置为：latitude（纬度，此时值（Value）为纬度值，例如 39.9800718）、longitude（经度，此时值（Value）为经度值，例如 116.309314）。​ |
| data.chat_config.user_id​ | String​ | 可选​ | 标识当前与智能体的用户，由使用方自行定义、生成与维护。user_id用于标识对话中的不同用户，不同的user_id，其对话的上下文消息、数据库等对话记忆数据互相隔离。如果不需要用户数据隔离，可将此参数固定为一个任意字符串，例如 123，abc 等。​ |
| data.chat_config.conversation_id​ | String​ | 可选​ | 标识对话发生在哪一次会话中。会话是智能体和用户之间的一段问答交互。一个会话包含一条或多条消息。对话是会话中对智能体的一次调用，智能体会将对话中产生的消息添加到会话中。可以使用已创建的会话，会话中已存在的消息将作为上下文传递给模型。创建会话的方式可参考创建会话。对于一问一答等不需要区分 conversation 的场合可不传该参数，系统会自动生成一个会话。不传的话会默认创建一个新的 conversation。​ |
| data.chat_config.auto_save_history​ | Boolean​ | 可选​ | 是否保存本次对话记录。​true：（默认）会话中保存本次对话记录，包括本次对话的模型回复结果、模型执行中间结果。​false：会话中不保存本次对话记录，后续也无法通过任何方式查看本次对话信息、消息详情。在同一个会话中再次发起对话时，本次会话也不会作为上下文传递给模型。​ |
| data.chat_config.parameters​ | Map<String, any>​ | 可选​ | 设置对话流的输入参数。​对话流的输入参数 USER_INPUT 应在 additional_messages 中传入，在 parameters 中的 USER_INPUT 不生效。​如果 parameters 中未指定 CONVERSATION_NAME 或其他输入参数，则使用参数默认值运行对话流；如果指定了这些参数，则使用指定值。​ |
| data.input_audio​ | Object​ | 必选​ | 输入音频格式。​ |
| data.input_audio.format​ | String​ | 必选​ | 输入音频的格式，支持pcm、wav、ogg。默认为wav。​ |
| data.input_audio.codec​ | String​ | 必选​ | 输入音频的编码，支持pcm、opus。默认为pcm。​ |
| data.input_audio.sample_rate​ | Integer​ | 必选​ | 输入音频的采样率，默认 24000。​ |
| data.input_audio.channel​ | Integer​ | 必选​ | 输入音频的声道数，默认是 1（单声道）。​ |
| data.input_audio.bit_depth​ | Integer​ | 必选​ | 输入音频的位深，默认是 16。​ |
| data.output_audio​ | Object​ | 必选​ | 输出音频格式。​ |
| data.output_audio.codec​ | String​ | 必选​ | 输出音频编码，支持pcm、g711a、g711u、opus、mp3。默认是pcm。​ |
| data.output_audio.pcm_config​ | Object​ | 可选​ | 当codec设置为opus时，不需要设置此字段。​ |
| data.output_audio.pcm_config.sample_rate​ | Integer​ | 可选​ | 输出pcm音频的采样率，默认 24000。​ |
| data.output_audio.pcm_config.frame_size_ms​ | Float​ | 可选​ | 输出每个 pcm 包的时长，单位 ms，默认不限制。​ |
| data.output_audio.pcm_config.limit_config​ | Object​ | 可选​ | 输出音频限流配置，默认不限制。​ |
| data.output_audio.pcm_config.limit_config.period​ | Integer​ | 可选​ | 周期的时长，单位为秒。例如设置为 10 秒，则以 10 秒作为一个周期。​ |
| data.output_audio.pcm_config.limit_config.max_frame_num​ | Integer​ | 可选​ | 周期内，最大返回 pcm 包数量。​ |
| data.output_audio.opus_config​ | Object​ | 可选​ | 当codec设置为pcm时，不需要设置此字段。​ |
| data.output_audio.opus_config.bitrate​ | Integer​ | 可选​ | 输出opus的码率，默认 48000。​ |
| data.output_audio.opus_config.use_cbr​ | Boolean​ | 可选​ | 输出opus是否使用 CBR 编码，默认为false。​ |
| data.output_audio.opus_config.frame_size_ms​ | Float​ | 可选​ | 输出opus的帧长，默认是 10。​ |
| data.output_audio.opus_config.limit_config​ | Object​ | 可选​ | 输出音频限流配置。​ |
| data.output_audio.opus_config.limit_config.period​ | Integer​ | 可选​ | 周期的时长，单位为秒。例如设置为 10 秒，则以 10 秒作为一个周期。​ |
| data.output_audio.opus_config.limit_config.max_frame_num​ | Integer​ | 可选​ | 周期内最大返回的 Opus 帧数量。​ |
| data.output_audio.mp3_config​ | Object​ | 可选​ | 当codec设置为mp3时，用于配置 mp3 音频参数。​当codec设置为opus、pcm、g711a、g711u时，不需要设置此字段。​ |
| data.output_audio.mp3_config.sample_rate​ | Integer​ | 可选​ | 输出mp3音频的采样率，默认是 44100。支持 32000，44100，48000。​ |
| data.output_audio.mp3_config.bit_rate​ | Integer​ | 可选​ | 输出mp3音频的码率，支持 8000~1600000。​ |
| data.output_audio.loudness_rate​ | Integer​ | 可选​ | 输出音频的音量，取值范围 [-50, 100]，默认为 0。-50 表示 0.5 倍音量，100 表示 2 倍音量。​ |
| data.output_audio.speech_rate​ | Integer​ | 必选​ | 输出音频的语速，取值范围 [-50, 100]，默认为 0。-50 表示 0.5 倍速，100 表示 2 倍速。​ |
| data.output_audio.voice_id​ | String​ | 可选​ | 输出音频的音色 ID。​ |
| data.output_audio.emotion_config​ | Object​ | 可选​ | 设置多情感音色的情感和情感值，仅当voice_id为多情感音色时才支持该配置。​ |
| data.output_audio.emotion_config.emotion​ | String​ | 可选​ | 设置多情感音色的情感类型。不同音色支持的情感范围不同，可以通过系统音色列表查看各音色支持的情感。默认为空。枚举值如下：​happy-开心​sad-悲伤​angry-生气​surprised-惊讶​fear-恐惧​hate-厌恶​excited-激动​coldness-冷漠​neutral-中性​ |
| data.output_audio.emotion_config.emotion_scale​ | Float​ | 可选​ | 情感值用于量化情感的强度。数值越高，情感表达越强烈，例如： “开心” 的情感值 5 比 1 更显兴奋。​取值范围：1.0~5.0，默认值：4.0。​ |
| data.voice_processing_config​ | Object​ | 可选​ | 语音处理能力配置。​说明仅扣子企业旗舰版支持该配置。​ |
| data.voice_processing_config.enable_ans​ | Boolean​ | 可选​ | 主动噪声抑制。自动识别并过滤掉背景环境中的各种噪音（如键盘声、空调声、街道嘈杂声），让说话者的声音更清晰。​此功能与下面的enable_pdns（声纹降噪）只能二选一开启，不能同时使用。​ |
| data.voice_processing_config.enable_pdns​ | Boolean​ | 可选​ | 声纹降噪。专门针对特定说话人的声音进行优化，能更精准地保留目标人声。​此功能与上面的enable_ans只能二选一开启，不能同时使用。​提供两种模式：​自动提取：设置简单，开箱即用。默认为该模式。降噪生效稍微有延迟，服务端需要先听你说一会儿话才能提取出你的声纹特征，在此期间降噪效果可能不佳。另外，提取声纹会受到用户说话场景影响，准确性上可能会弱于主动设置。​主动设置：降噪效果更精准、更快速，在对话开始时就立即生效。不过需要提前录制声纹并在voice_print_feature_id中设置声纹 ID。​ |
| data.voice_processing_config.voice_print_feature_id​ | String​ | 可选​ | 目标说话人的声纹 ID。当你选择开启enable_pdns（声纹降噪）并希望使用主动设置模式时，需要在此处填入你提前录制好的声纹 ID。​ |
| data.turn_detection​ | Object​ | 可选​ | 转检测配置。​ |
| data.turn_detection.type​ | String​ | 可选​ | 语音检测类型，用于控制语音交互的检测方式，枚举值：​server_vad：自由对话模式，语音数据会传输到服务器端进行实时分析，服务器端的语音活动检测算法会判断用户是否在说话。​client_interrupt：（默认）按键说话模式，由客户端控制语音的开始与结束。​semantic_vad：采用语义判停的自由对话模式（此功能仅对企业旗舰版用户开放），由服务端识别说话人的说话的语义判断是否停止说话。​ |
| data.turn_detection.prefix_padding_ms​ | Integer​ | 可选​ | server_vad模式下，VAD 检测到语音之前要包含的音频量，单位为 ms。默认为 600ms。​ |
| data.turn_detection.silence_duration_ms​ | Integer​ | 可选​ | server_vad模式下，检测语音停止的静音持续时间，单位为 ms。默认为 500ms。​ |
| data.turn_detection.semantic_vad_config​ | Object​ | 可选​ | semantic_vad模式下，配置判定语音停止的语义检测策略。​ |
| data.turn_detection.semantic_vad_config.silence_threshold_ms​ | Integer​ | 可选​ | 当用户暂停说话时，持续静音多久后，触发语义判停检测。单位为 ms。默认为 300ms。​ |
| data.turn_detection.semantic_vad_config.semantic_unfinished_wait_time_ms​ | Integer​ | 可选​ | 当语义检测判断该语句未结束时，持续静音多久后，扣子认定语音结束。单位为 ms。默认为 500ms。​ |
| data.turn_detection.interrupt_config​ | Object​ | 可选​ | server_vad模式下，配置语音对话的打断策略。​默认采用发声即打断模式，即在检测到语音输入时会中断智能体的输出。​ |
| data.turn_detection.interrupt_config.mode​ | String​ | 可选​ | 配置通过关键词打断，包括:​keyword_contains模式下，说话内容包含关键词才会打断模型回复。例如关键词"扣子"，用户正在说“你好呀扣子......” / “扣子你好呀”，模型回复都会被打断。​keyword_prefix模式下，说话内容前缀匹配关键词才会打断模型回复。例如关键词"扣子"，用户正在说“扣子你好呀......”，模型回复就会被打断，而用户说“你好呀扣子......”，模型回复不会被打断。​详细配置方法请参见​通过关键词打断语音对话。​ |
| data.turn_detection.interrupt_config.keywords​ | Array<String>​ | 可选​ | 打断的关键词配置，最多同时限制 5 个关键词，每个关键词限定长度在 6~24 个字节以内（2~8个汉字以内），不能有标点符号。​ |
| data.asr_config​ | Object​ | 可选​ | 语音识别配置，包括热词和上下文信息，以便优化语音识别的准确性和相关性。​ |
| data.asr_config.hot_words​ | Array<String>​ | 可选​ | 请输入热词列表，以便提升这些词汇的识别准确率。如果设置的热词数量超出以下数量限制，超出部分将自动截断。​data.asr_config.stream_mode为output_no_stream时：hot_words 支持 5000 tokens。​data.asr_config.stream_mode为bidirectional_stream时： hot_words 支持 100 tokens。​ |
| data.asr_config.context​ | String​ | 可选​ | 请输入上下文信息。​最多输入 800 个 Tokens，超出部分将自动截断。​ |
| data.asr_config.user_language​ | String​ | 可选​ | 用户说话的语种，默认为common。选项包括：​common：大模型语音识别，支持中英文、上海话、闽南语，四川、陕西、粤语识别。​英语：en-US​日语：ja-JP​印尼语：id-ID​西班牙语：es-MX​葡萄牙语：pt-BR​德语：de-DE​法语：fr-FR​韩语：ko-KR​菲律宾语：fil-PH​马来语：ms-MY​泰语：th-TH​阿拉伯语：ar-SA​ |
| data.asr_config.enable_ddc​ | Boolean​ | 可选​ | 将语音转为文本时，是否启用语义顺滑。默认为true。​true：系统在进行语音处理时，会去掉识别结果中诸如 “啊”“嗯” 等语气词，使得输出的文本语义更加流畅自然，符合正常的语言表达习惯，尤其适用于对文本质量要求较高的场景，如正式的会议记录、新闻稿件生成等。​false：系统不会对识别结果中的语气词进行处理，识别结果会保留原始的语气词。​ |
| data.asr_config.enable_itn​ | Boolean​ | 可选​ | 将语音转为文本时，是否开启文本规范化（ITN）处理，将识别结果转换为更符合书面表达习惯的格式以提升可读性。默认为true。​开启后，会将口语化数字转换为标准数字格式，示例：​将两点十五分转换为14:15。​将一百美元转换为$100。​ |
| data.asr_config.enable_punc​ | Boolean​ | 可选​ | 将语音转为文本时，是否给文本加上标点符号。默认为true。​ |
| data.asr_config.stream_mode​ | String​ | 可选​ | ASR 识别的模式。​output_no_stream：不会逐字返回语音识别结果，而是等整段语音结束后统一输出完整文本。异步语音消息场景中推荐使用该模式，会整合整句音频信息做上下文分析，减少实时截断导致的误差，提升准确率。​bidirectional_stream（默认值）：逐字的返回语音识别的结果。​ |
| data.asr_config.enable_nostream​ | Boolean​ | 可选​ | 是否开启二次识别模式：​true：会实时返回逐字识别的文本；当一句话结束时，会结合整句音频进行上下文分析并重新识别，生成优化后的识别结果并返回。这种机制既能满足客户实时上屏的需求，又能确保最终结果的识别准确率。​false（默认值）：仅进行一次实时识别，逐字返回文本，不会在一句话结束时重新识别分句，可能存在一定的识别误差。​ |
| data.asr_config.enable_emotion​ | Boolean​ | 可选​ | 识别说话人的情绪。仅在data.asr_config.stream_mode为output_no_stream时生效。默认为false。​支持的情绪标签包括：​angry：表示情绪为生气​happy：表示情绪为开心​neutral：表示情绪为平静或中性​sad：表示情绪为悲伤​surprise：表示情绪为惊讶​ |
| data.asr_config.enable_gender​ | Boolean​ | 可选​ | 是否开启识别说话人的性别（male/female），仅在data.asr_config.stream_mode为output_no_stream时生效。默认为false。​ |
| data.asr_config.sensitive_words_filter​ | Object​ | 可选​ | 敏感词过滤功能，支持以下 3 种过滤方式：​过滤系统敏感词，并替换为*。​过滤自定义敏感词，并替换为空。​过滤自定义敏感词，并替换为*。​ |
| data.asr_config.sensitive_words_filter.system_reserved_filter​ | Boolean​ | 可选​ | 是否过滤系统自带的敏感词，并将匹配到的敏感词替换为*。（系统自带敏感词主要包含一些限制级词汇）。默认为false。​ |
| data.asr_config.sensitive_words_filter.filter_with_empty​ | Array<string>​ | 可选​ | 自定义需替换为空的敏感词列表。​ |
| data.asr_config.sensitive_words_filter.filter_with_signed​ | Array<string>​ | 可选​ | 自定义需替换为*的敏感词列表。​ |
| data.voice_print_config​ | Object<String>​ | 可选​ | 声纹识别配置。​ |
| data.voice_print_config.group_id​ | String​ | 可选​ | 声纹组 ID。语音通话时，扣子会在该声纹组内进行查找匹配对应的声纹，当声纹匹配度高于score阈值，则认为是同一个人的声音。​ |
| data.voice_print_config.score​ | Integer​ | 可选​ | 声纹匹配的命中阈值，即声音匹配度的最低标准。当声音匹配度达到或超过该阈值时，扣子才会认定声纹匹配成功。你可以根据应用的安全性要求进行自定义设置。如果匹配了多轮声纹，扣子会取相似度最高的一个。​取值范围：0~100，默认值：40。​ |
| data.voice_print_config.reuse_voice_info​ | Boolean​ | 可选​ | 当本轮对话未命中任何声纹时，是否沿用历史声纹信息。​true：未命中声纹时，智能体将返回上一次命中的声纹。适用于连续对话场景，当收音不好等情况导致声纹没能正确被识别时，保障对话的连贯性。​false：（默认值）未命中声纹时，智能体返回空的声纹信息。​ |
| detail​ | Object​ | 必选​ | 事件详情。​ |
| detail.logid​ | String​ | 必选​ | 本次请求的日志 ID。如果遇到异常报错场景，且反复重试仍然报错，可以根据此 logid 及错误码联系扣子团队获取帮助。详细说明可参考获取帮助和技术支持。​ |

- true ：（默认）会话中保存本次对话记录，包括本次对话的模型回复结果、模型执行中间结果。 ​

- false ：会话中不保存本次对话记录，后续也无法通过任何方式查看本次对话信息、消息详情。在同一个会话中再次发起对话时，本次会话也不会作为上下文传递给模型。 ​

- 对话流的输入参数 USER_INPUT 应在 additional_messages 中传入，在 parameters 中的 USER_INPUT 不生效。 ​

- 如果 parameters 中未指定 CONVERSATION_NAME 或其他输入参数，则使用参数默认值运行对话流；如果指定了这些参数，则使用指定值。 ​

- 当 codec 设置为 mp3 时，用于配置 mp3 音频参数。 ​

- 当 codec 设置为 opus 、 pcm 、 g711a 、 g711u 时，不需要设置此字段。 ​

- happy-开心 ​

- sad-悲伤 ​

- angry-生气 ​

- surprised-惊讶 ​

- fear-恐惧 ​

- hate-厌恶 ​

- excited-激动 ​

- coldness-冷漠 ​

- neutral-中性 ​

- 自动提取：设置简单，开箱即用。默认为该模式。 降噪生效稍微有延迟 ，服务端需要先听你说一会儿话才能提取出你的声纹特征，在此期间降噪效果可能不佳。另外，提取声纹会受到用户说话场景影响，准确性上可能会弱于主动设置。 ​

- 主动设置： 降噪效果更精准、更快速 ，在对话开始时就立即生效。不过需要提前录制声纹并在 voice_print_feature_id 中设置声纹 ID。 ​

- server_vad ：自由对话模式，语音数据会传输到服务器端进行实时分析，服务器端的语音活动检测算法会判断用户是否在说话。 ​

- client_interrupt ：（默认）按键说话模式，由客户端控制语音的开始与结束。 ​

- semantic_vad ：采用语义判停的自由对话模式（ 此功能仅对企业旗舰版用户开放 ），由服务端识别说话人的说话的语义判断是否停止说话。 ​

- keyword_contains 模式下，说话内容 包含 关键词才会打断模型回复。例如关键词"扣子"，用户正在说“你好呀扣子......” / “扣子你好呀”，模型回复都会被打断。 ​

- keyword_prefix 模式下，说话内容 前缀匹配 关键词才会打断模型回复。例如关键词"扣子"，用户正在说“扣子你好呀......”，模型回复就会被打断，而用户说“你好呀扣子......”，模型回复不会被打断。 ​

- data.asr_config.stream_mode 为 output_no_stream 时：hot_words 支持 5000 tokens。 ​

- data.asr_config.stream_mode 为 bidirectional_stream 时： hot_words 支持 100 tokens。 ​

- common：大模型语音识别，支持中英文、上海话、闽南语，四川、陕西、粤语识别。 ​

- 英语：en-US ​

- 日语：ja-JP ​

- 印尼语：id-ID ​

- 西班牙语：es-MX ​

- 葡萄牙语：pt-BR ​

- 德语：de-DE ​

- 法语：fr-FR ​

- 韩语：ko-KR ​

- 菲律宾语：fil-PH ​

- 马来语：ms-MY ​

- 泰语：th-TH ​

- 阿拉伯语：ar-SA ​

- true ：系统在进行语音处理时，会去掉识别结果中诸如 “啊”“嗯” 等语气词，使得输出的文本语义更加流畅自然，符合正常的语言表达习惯，尤其适用于对文本质量要求较高的场景，如正式的会议记录、新闻稿件生成等。 ​

- false ：系统不会对识别结果中的语气词进行处理，识别结果会保留原始的语气词。 ​

- 将 两点十五分 转换为 14:15 。 ​

- 将 一百美元 转换为 $100 。 ​

- output_no_stream ：不会逐字返回语音识别结果，而是等整段语音结束后统一输出完整文本。异步语音消息场景中推荐使用该模式，会整合整句音频信息做上下文分析，减少实时截断导致的误差，提升准确率。 ​

- bidirectional_stream （默认值）：逐字的返回语音识别的结果。 ​

- true ：会实时返回逐字识别的文本；当一句话结束时，会结合整句音频进行上下文分析并重新识别，生成优化后的识别结果并返回。这种机制既能满足客户实时上屏的需求，又能确保最终结果的识别准确率。 ​

- false （默认值）：仅进行一次实时识别，逐字返回文本，不会在一句话结束时重新识别分句，可能存在一定的识别误差。 ​

- angry ：表示情绪为生气 ​

- happy ：表示情绪为开心 ​

- neutral ：表示情绪为平静或中性 ​

- sad ：表示情绪为悲伤 ​

- surprise ：表示情绪为惊讶 ​

- 过滤系统敏感词，并替换为 * 。 ​

- 过滤自定义敏感词，并替换为空。 ​

- 过滤自定义敏感词，并替换为 * 。 ​

- true ：未命中声纹时，智能体将返回上一次命中的声纹。适用于连续对话场景，当收音不好等情况导致声纹没能正确被识别时，保障对话的连贯性。 ​

- false ：（默认值）未命中声纹时，智能体返回空的声纹信息。 ​

- 事件示例 ： ​

- 事件类型 ： conversation.chat.created ​

- 事件说明 ：创建对话的事件，表示对话开始。 ​

- 事件结构 ： ​

- 事件示例 ： ​

- 事件类型 ： conversation.chat.in_progress ​

- 事件说明 ：服务端正在处理对话。 ​

- 事件结构 ： ​

- 事件示例 ： ​

- 事件类型 ： conversation.message.delta ​

- 事件说明 ：增量消息，通常是 type=answer 时的增量消息。 ​

- 事件结构 ： ​

- 事件示例 ： ​

- 事件类型： conversation.audio.sentence_start ​

- 事件说明 ：一条新的字幕句子，后续的 conversation.audio.delta 增量语音均属于当前字幕句子，可能有多个增量语音共同对应此句字幕的文字内容。 ​

- 事件结构： ​

- ​

- 事件示例 ： ​

- ​

- 事件类型 ： conversation.audio.delta ​

- 事件说明 ：增量语音，通常是 type=answer 时的增量语音。 ​

- 事件结构 ： ​

- 事件示例 ： ​

- 事件类型 ： conversation.message.completed ​

- 事件说明 ：消息已回复完成。此时事件中带有所有 message.delta 的拼接结果，且每个消息均为 completed 状态。 ​

- 事件结构 ： ​

- 事件示例 ： ​

- 事件类型 ： conversation.audio.completed ​

- 事件说明 ：音频回复完成。 ​

- 事件结构 ： ​

- 事件示例 ： ​

- 事件类型 ： conversation.chat.completed ​

- 事件说明 ：表示对话已完成。 ​

- 事件结构 ： ​

- 事件示例 ： ​

- 事件类型 ： conversation.chat.failed ​

- 事件说明 ：此事件用于标识对话失败。 ​

- 事件结构 ： ​

- ​

- 事件示例 ： ​

- ​

- 事件类型 ： error ​

- 事件说明 ：对话过程中的错误事件。 ​

- 事件结构 ： ​

- ​

- 事件示例 ： ​

- ​

- 事件类型 ： input_audio_buffer.completed ​

- 事件说明 ：流式提交的音频完成后，返回此事件。 ​

- 事件结构 ： ​

- ​

- 事件示例 ： ​

- ​

- 事件类型 ： input_audio_buffer.cleared ​

- 事件说明 ：清除缓冲区音频成功后，返回此事件。 ​

- 事件结构 ： ​

- ​

- 事件示例 ： ​

- ​

- 事件类型 ： conversation.cleared ​

- 事件说明 ：清除上下文成功后，返回此事件。 ​

- 事件结构 ： ​

- ​

- 事件示例 ： ​

- ​

- 事件类型 ： conversation.chat.canceled ​

- 事件说明 ：客户端提交 conversation.chat.cancel 事件，服务端完成中断后，将返回此事件。 ​

- 事件结构 ： ​

- ​

- 事件示例 ： ​

- 事件类型 ： conversation.audio_transcript.update ​

- 事件说明 ：用户语音识别的中间值，每次返回都是全量文本。 ​

- 事件结构 ： ​

- ​

- 事件示例 ： ​

- ​

- 事件类型 ： conversation.audio_transcript.completed ​

- 事件说明 ：用户语音识别完成。 ​

- 事件结构 ： ​

- ​

- 事件示例 ： ​

- ​

- 事件类型 ： conversation.chat.requires_action ​

- 事件说明 ：对话中断，需要使用方上报工具的执行结果。 ​

- 事件结构 ： ​

- ​

- 事件示例 ： ​

- ​

- 事件类型 ： input_audio_buffer.speech_started ​

- 事件说明 ：此事件表示服务端识别到用户正在说话。只有在 server_vad 模式下，才会返回此事件。 ​

- 事件结构 ： ​

- ​

- 事件示例 ： ​

- 事件类型 ： input_audio_buffer.speech_stopped ​

- 事件说明 ：此事件表示服务端识别到用户已停止说话。只有在 server_vad 模式下，才会返回此事件。 ​

- 事件结构 ： ​

- ​

- 事件示例 ： ​